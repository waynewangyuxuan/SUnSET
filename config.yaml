# SUnSET Configuration

llm:
  provider: "openai"  # "openai" or "vllm"

  # OpenAI settings (set OPENAI_API_KEY env var)
  openai_model: "gpt-4o"

  # VLLM settings (alternative)
  vllm_url: "http://ds-serv11.ucsd.edu:18000/v1"
  vllm_model: "Qwen/Qwen3-32B"

  temperature: 0.0
  max_tokens: 4096

embedding:
  provider: "local"  # "local" for GTE-Modernbert-Base, "api" for remote
  local_model: "Alibaba-NLP/gte-modernbert-base"  # Paper's embedding model
  # API settings (if provider="api")
  url: "http://ds-serv11.ucsd.edu:18003/v1"
  model: "qwen3-embed-0.6b"
  batch_size: 100

wikidata:
  proxy_url: "https://proxy.frederickpi.com/proxy/random/normal"
  cache_file: "entity_cache.json"
  max_concurrent: 5
  timeout: 30

pipeline:
  beta: 1.0                        # Relevance scaling
  em_n: 1                          # BoolEM_n threshold
  top_k: 20                        # Top-k neighbors
  max_stakeholders_per_event: 5
  max_timeline_entries: 50

logging:
  level: "INFO"
  format: "text"  # "json" or "text"

data_path: "timeline17.pkl"
results_dir: "results"
